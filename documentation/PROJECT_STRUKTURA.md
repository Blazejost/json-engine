# JSON Engine - Struktura Projektu i Wzorce

## ğŸ“ Struktura KatalogÃ³w

```
json-engine/
â”œâ”€â”€ json_engine/              # GÅ‚Ã³wny package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tokenizer.py          # Tokenizacja JSON
â”‚   â”œâ”€â”€ parser.py             # Parsowanie do struktur Python
â”‚   â”œâ”€â”€ encoder.py            # Encodowanie do JSON
â”‚   â””â”€â”€ api.py                # Publiczne API (loads, dumps, load, dump)
â”‚
â”œâ”€â”€ tests/                    # Testy automatyczne
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py           # Pytest fixtures
â”‚   â”œâ”€â”€ test_tokenizer.py    # 69+ testÃ³w tokenizera
â”‚   â”œâ”€â”€ test_parser.py        # 52+ testÃ³w parsera
â”‚   â”œâ”€â”€ test_encoder.py       # 48+ testÃ³w enkodera
â”‚   â”œâ”€â”€ test_api.py           # 45+ testÃ³w API
â”‚   â””â”€â”€ test_integration.py   # 40+ testÃ³w integracyjnych
â”‚
â”œâ”€â”€ demo_basic_api.py         # Demo aplikacji
â”œâ”€â”€ pyproject.toml            # Konfiguracja projektu (uv)
â”œâ”€â”€ pytest.ini                # Konfiguracja pytest
â”œâ”€â”€ README.md                 # Dokumentacja gÅ‚Ã³wna
â”œâ”€â”€ README_TESTING.md         # Dokumentacja testÃ³w
â””â”€â”€ PROJEKT_STRUKTURA.md      # Ten plik
```

## ğŸ—ºï¸ Schemat Graficzny Struktury Systemu

```mermaid
flowchart LR
    A[UÅ¼ytkownik] --> B[API: loads/dumps/load/dump]
    B --> C[JSONDecoder]
    B --> D[JSONEncoder]
    C --> E[Tokenizer]
    E --> F[Tokeny]
    C --> G[Struktury Python]
    D --> H[JSON string]

    subgraph ModuÅ‚y
        B
        C
        D
        E
    end

    subgraph Testy
        T1[test_tokenizer.py]
        T2[test_parser.py]
        T3[test_encoder.py]
        T4[test_api.py]
        T5[test_integration.py]
    end

    T1 -.-> E
    T2 -.-> C
    T3 -.-> D
    T4 -.-> B
    T5 -.-> B
```

## ğŸ—ï¸ Wzorce Architektoniczne

### 1. **Separation of Concerns**

KaÅ¼dy moduÅ‚ ma jednÄ…, wyraÅºnÄ… odpowiedzialnoÅ›Ä‡:

- **tokenizer.py**: Tylko tokenizacja - przeksztaÅ‚canie tekstu na tokeny
- **parser.py**: Tylko parsowanie - tokeny â†’ struktury Python
- **encoder.py**: Tylko encodowanie - struktury Python â†’ JSON string
- **api.py**: Fasada - uproszczony interfejs dla uÅ¼ytkownika

```python
# PrzykÅ‚ad SoC
# Tokenizer NIE parsuje, tylko tokenizuje
def tokenize(json_string: str) -> Generator[Token, None, None]:
    # ... tylko tworzenie tokenÃ³w

# Parser NIE tokenizuje, tylko parsuje
class JSONDecoder:
    def decode(self, s: str) -> Any:
        self.tokens = list(tokenize(s))  # uÅ¼yj tokenizera
        # ... tylko parsowanie
```

### 2. **Strategy Pattern**

Parser uÅ¼ywa rÃ³Å¼nych strategii dla rÃ³Å¼nych typÃ³w wartoÅ›ci:

```python
def parse_value():
    tok = self._peek()
    if tok.type == '{':
        return parse_object()    # Strategia dla obiektÃ³w
    if tok.type == '[':
        return parse_array()     # Strategia dla tablic
    if tok.type == 'STRING':
        return tok.value         # Strategia dla stringÃ³w
    # ...
```

**Zalety**:
- Åatwe dodanie nowych typÃ³w
- Kod jest czytelny i rozszerzalny
- Zgodne z Open/Closed Principle

### 3. **Single Responsibility Principle (SRP)**

KaÅ¼da klasa ma jednÄ… odpowiedzialnoÅ›Ä‡:

```python
# Token - tylko przechowywanie informacji o tokenie
class Token:
    def __init__(self, type_: str, value: str, line: int, column: int):
        # Tylko dane, bez logiki

# JSONDecoder - tylko parsowanie
class JSONDecoder:
    def decode(self, s: str) -> Any:
        # Tylko logika parsowania

# JSONEncoder - tylko encodowanie
class JSONEncoder:
    def encode(self, obj: Any) -> str:
        # Tylko logika encodowania
```

### 4. **Facade Pattern**

API dostarcza prostÄ… fasadÄ™ dla zÅ‚oÅ¼onego systemu:

```python
# api.py - prosta fasada
def loads(s: str) -> Any:
    decoder = JSONDecoder()
    return decoder.decode(s)

def dumps(obj: Any) -> str:
    encoder = JSONEncoder()
    return encoder.encode(obj)
```

**Zalety**:
- UÅ¼ytkownik nie musi znaÄ‡ szczegÃ³Å‚Ã³w implementacji
- Åatwe w uÅ¼yciu API
- Zgodne z Pythonowym `json` module

### 5. **Iterator Pattern**

Tokenizer zwraca generator (iterator):

```python
def tokenize(json_string: str) -> Generator[Token, None, None]:
    # ...
    yield Token(type_, value, line, col)
```

**Zalety**:
- Leniwa ewaluacja
- PamiÄ™Ä‡ wydajna dla duÅ¼ych plikÃ³w
- Standardowy Python pattern

## ğŸ“Š Struktury Danych

### 1. **Token - Klasa Danych**

```python
class Token:
    type: str      # Typ tokenu (STRING, NUMBER, '{', ...)
    value: str     # WartoÅ›Ä‡ tokenu
    line: int      # Numer linii (dla bÅ‚Ä™dÃ³w)
    column: int    # Numer kolumny (dla bÅ‚Ä™dÃ³w)
```

**Uzasadnienie**: 
- Proste, immutable dane
- UÅ‚atwia debugowanie (linia i kolumna)
- Type hints dla bezpieczeÅ„stwa typÃ³w

### 2. **Lista TokenÃ³w w Parserze**

```python
class JSONDecoder:
    tokens: List[Token]  # Wszystkie tokeny
    pos: int             # Aktualna pozycja
```

**Uzasadnienie**:
- Random access do tokenÃ³w (peek ahead)
- Åatwe backtracking jeÅ›li potrzebne
- Alternatywa: generator - ale trudniejszy peek

**Trade-off**:
- âœ… Åatwy w implementacji
- âœ… Szybki random access
- âŒ WiÄ™cej pamiÄ™ci dla duÅ¼ych plikÃ³w

### 3. **Dictionary dla ObiektÃ³w JSON**

```python
def parse_object():
    obj = {}  # Python dict
    # ...
    obj[key] = value
    return obj
```

**Uzasadnienie**:
- Naturalne mapowanie JSON object â†’ Python dict
- O(1) lookup
- Standardowy Python typ

### 4. **List dla Tablic JSON**

```python
def parse_array():
    arr = []  # Python list
    # ...
    arr.append(value)
    return arr
```

**Uzasadnienie**:
- Naturalne mapowanie JSON array â†’ Python list
- Zachowana kolejnoÅ›Ä‡
- Dynamiczny rozmiar

## ğŸ§® Algorytmy

### 1. **Tokenizacja - Finite State Machine**

```python
while i < length:
    ch = json_string[i]
    
    if ch in '{}[]:,':
        # Stan: pojedynczy znak
        yield Token(ch, ch, line, col)
    
    elif ch == '"':
        # Stan: string
        # ... zbieraj znaki do zamkniÄ™cia "
    
    elif ch.isdigit() or ch == '-':
        # Stan: liczba
        # ... uÅ¼yj regex do walidacji
```

**ZÅ‚oÅ¼onoÅ›Ä‡**: O(n) gdzie n = dÅ‚ugoÅ›Ä‡ stringa
**Uzasadnienie**: Pojedyncze przejÅ›cie przez string

### 2. **Parsowanie - Recursive Descent Parser**

```python
def parse_value():
    if is_object():
        return parse_object()  # Rekursja
    if is_array():
        return parse_array()   # Rekursja
    return parse_primitive()

def parse_object():
    # ...
    value = parse_value()  # Rekurencyjne wywoÅ‚anie
```

**ZÅ‚oÅ¼onoÅ›Ä‡**: O(n) gdzie n = liczba tokenÃ³w
**Uzasadnienie**: 
- Czytelny kod
- Naturalne dla zagnieÅ¼dÅ¼onych struktur
- Zgodny z gramatykÄ… JSON

### 3. **Encodowanie - Rekurencyjna Serializacja**

```python
def encode(self, obj: Any) -> str:
    if isinstance(obj, dict):
        # Rekursja dla wartoÅ›ci
        items = [f"{self.encode(k)}: {self.encode(v)}" 
                 for k, v in obj.items()]
        return "{" + ", ".join(items) + "}"
```

**ZÅ‚oÅ¼onoÅ›Ä‡**: O(n) gdzie n = liczba elementÃ³w
**Uzasadnienie**: KaÅ¼dy element odwiedzany raz

## ğŸ¯ Zasady Projektowania Obiektowego

### 1. **SOLID Principles**

#### Single Responsibility (âœ…)
- Token - tylko dane
- Tokenizer - tylko tokenizacja
- Parser - tylko parsowanie
- Encoder - tylko encodowanie

#### Open/Closed (âœ…)
- Åatwo dodaÄ‡ nowy typ wartoÅ›ci do parsera
- Encoder extensible dla nowych typÃ³w

#### Liskov Substitution (N/A)
- Brak hierarchii dziedziczenia

#### Interface Segregation (âœ…)
- API minimalne i konkretne
- KaÅ¼da funkcja robi jednÄ… rzecz

#### Dependency Inversion (âœ…)
- Parser zaleÅ¼y od abstrakcji Token
- API zaleÅ¼y od abstrakcji Decoder/Encoder

### 2. **DRY (Don't Repeat Yourself)**

```python
# Zamiast powielaÄ‡ kod dla kaÅ¼dego typu:
def parse_value():
    # Jedna funkcja, rÃ³Å¼ne Å›cieÅ¼ki
    # Brak duplikacji
```

### 3. **YAGNI (You Aren't Gonna Need It)**

- Brak nadmiarowych features
- Tylko to co wymagane przez specyfikacjÄ™ JSON
- Proste, dziaÅ‚ajÄ…ce rozwiÄ…zania

## ğŸ“ˆ Metryki JakoÅ›ci Kodu

### Coverage (oczekiwane)

```
tokenizer.py     > 95%
parser.py        > 90%
encoder.py       > 95%
api.py           > 95%
-------------------------
TOTAL            > 92%
```

### KompleksnoÅ›Ä‡ (Cyclomatic Complexity)

- tokenize(): ~8 (akceptowalne)
- parse_value(): ~7 (akceptowalne)
- encode(): ~8 (akceptowalne)

**Target**: < 10 dla wszystkich funkcji

### Maintainability Index

- **Target**: > 70 (High maintainability)
- **Current**: ~85 (estimated)

## ğŸ” Design Decisions

### Dlaczego Lista TokenÃ³w zamiast Generatora w Parserze?

**Decyzja**: Lista
**Alternatywa**: Generator

**Uzasadnienie**:
- âœ… Peek ahead Å‚atwy (patrz na nastÄ™pny token)
- âœ… Lepsze error messages (znamy pozycjÄ™)
- âœ… Prostszy kod parsera
- âŒ WiÄ™cej pamiÄ™ci

**Kiedy uÅ¼yÅ‚bym generatora**: 
Dla streaming parsera duÅ¼ych plikÃ³w (GB+)

### Dlaczego Regex dla Liczb?

**Decyzja**: Regex
**Alternatywa**: RÄ™czna walidacja

**Uzasadnienie**:
- âœ… DokÅ‚adne dopasowanie do specyfikacji JSON
- âœ… Mniej kodu
- âœ… Åatwiejsze testy
- âŒ Nieco wolniejsze (ale pomijalne)

### Dlaczego Osobne Klasy Decoder/Encoder?

**Decyzja**: Osobne klasy
**Alternatywa**: Funkcje

**Uzasadnienie**:
- âœ… Stan (self.tokens, self.pos)
- âœ… MoÅ¼liwoÅ›Ä‡ rozszerzenia (trace mode)
- âœ… Jasna struktura
- âœ… Åatwiejsze testowanie

## ğŸ“š Bibliografia WzorcÃ³w

1. **Gang of Four** - Strategy, Facade, Iterator
2. **SOLID Principles** - Robert C. Martin
3. **Recursive Descent Parsing** - Standardowy algorytm parserÃ³w

## ğŸ“ Dla Prezentacji

### Kluczowe Punkty do Pokazania

1. **Separation of Concerns**: 4 moduÅ‚y, 4 odpowiedzialnoÅ›ci
2. **Strategy Pattern**: parse_value() jako dispatcher
3. **Facade Pattern**: Proste API (loads/dumps)
4. **Struktury danych**: Token, List[Token], Dict, List
5. **Algorytmy**: O(n) tokenizacja i parsowanie
6. **Testy**: 250+ testÃ³w, >90% coverage
7. **SOLID**: SRP w kaÅ¼dej klasie

### Demo Flow

```bash
# 1. PokaÅ¼ strukturÄ™
tree json_engine/

# 2. PokaÅ¼ testy
uv run pytest --collect-only

# 3. Uruchom testy z coverage
uv run pytest --cov=json_engine --cov-report=term

# 4. PokaÅ¼ konkretne testy
uv run pytest tests/test_integration.py -v

# 5. PokaÅ¼ error handling
uv run pytest tests/test_parser.py::TestErrorHandling -v
```